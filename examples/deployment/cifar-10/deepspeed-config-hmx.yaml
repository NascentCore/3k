apiVersion: kubeflow.org/v1
kind: MPIJob
metadata:
  name: dp-mpijob
spec:
  # This is required to enabled true distributed training.
  # Setting this to 1 will create 3 separate 8-GPU training jobs.
  slotsPerWorker: 1
  runPolicy:
    cleanPodPolicy: All
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          hostIPC: True
          volumes:
            - name: mpi-storage
              persistentVolumeClaim:
                claimName: mpi-data-pvc
          containers:
          - image: swr.cn-east-3.myhuaweicloud.com/sxwl/cifards:v0.0.7
            name: deepspeed-mpijob-container
            imagePullPolicy: IfNotPresent
            volumeMounts:
              - mountPath: "/deepspeed/DeepSpeedExamples/training/cifar/data"
                name: mpi-storage
            command:
            - mpirun
            - --allow-run-as-root
            - -bind-to
            - none
            - -map-by
            - slot
            - -x
            - NCCL_DEBUG=INFO
            - -x
            # The NCCL_P2P_DISABLE variable disables the peer to peer (P2P) transport,
            # which uses CUDA direct access between GPUs, using NVLink or PCI.
            - NCCL_P2P_DISABLE=1
            - -x
            - LD_LIBRARY_PATH
            - -x
            - PATH
            - -mca
            - mpi_warn_on_fork 
            - "0"
            - python3
            - /deepspeed/DeepSpeedExamples/training/cifar/cifar10_deepspeed.py
            - --deepspeed_mpi
            - --deepspeed
            - --deepspeed_config
            - /deepspeed/DeepSpeedExamples/training/cifar/ds_config.json
    Worker:
      replicas: 3
      template:
        spec:
          hostIPC: True
          volumes:
            - name: mpi-storage
              persistentVolumeClaim:
                claimName: mpi-data-pvc 
          containers:
          - image: swr.cn-east-3.myhuaweicloud.com/sxwl/cifards:v0.0.7
            name: deepspeed-mpijob-container
            imagePullPolicy: IfNotPresent
            resources:
              limits:
                nvidia.com/gpu: 8
            volumeMounts:
              - mountPath: "/deepspeed/DeepSpeedExamples/training/cifar/data"
                name: mpi-storage
