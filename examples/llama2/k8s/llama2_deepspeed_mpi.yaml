apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: llama2-finetuning-deepspeed
spec:
  slotsPerWorker: 2
  runPolicy:
    cleanPodPolicy: None  # No pods will be deleted after the job terminates.
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          hostIPC: True  # Setting True for now. Subject to change.
          containers:
          - name: llama2-training-deepspeed-mpi
            image: dockerhub.kubekey.local/kubesphereio/llama2_demo:2023-10-25
            imagePullPolicy: IfNotPresent
            command:
            - mpirun
            - x
            - RANK
            - -x
            - NCCL_DEBUG=WARN
            - -x
            - NCCL_P2P_LEVEL=SYS
            - -x
            - NCCL_IB_CUDA_SUPPORT=1
            - -x
            - NCCL_DEBUG_SUBSYS=ALL
            - -x
            - NCCL_IB_GDR_LEVEL=SYS
            - -x
            - NCCL_NET_GDR_LEVEL=SYS
            - -x
            - NCCL_NET_GDR_READ=1
            - -x
            - NCCL_NET=IB
            - -x
            - PATH
            #- -x
            #- NCCL_SOCKET_IFNAME=ibs1
            #- -x
            #- NCCL_IB_HCA=mlx5_
            - -np
            - "4"
            - --allow-run-as-root  # Running on GPU in containers.
            - --nooversubscribe
            - --bind-to
            - none
            - --map-by
            - slot
            - -mca
            - pml ob1  # Uses MPI P2P messaging.
            #- -mca
            #- btl ^openib  # We don't want to disables IB.
            - mca
            - mpi_warn_on_fork
            - "0"
            # All nodes where training processes run, including 1 master and 1+ workers. Please reach out to Glen to talk about this.
            #- -H
            # Node configurations, includong host names, slots, etc. Please reach out to Glen to talk about this.
            # Three notes about "--hostfile":
            # 1) In the context of MPI operator on K8s, this should be totally optional. Distribution is auto achieved based on the config of "replicas".
            # 2) This is supposed to be automatically generated by MPI operator and the default path is /etc/mpi/hostfile.
            # 3) Then, `mpirun` can take something like `--hostfile /etc/mpi/hostfile`.
            - --hostfile
            - /etc/mpi/hostfile
            - python3
            - llama2_demo.py
            env:
            - name: NCCL_TREE_THRESHOLD
              value: "0"  # Set NCCL tree threshold to 0 for DeepSpeed.
            - name: NCCL_ALGO
              value: "1"  # Set NCCL_ALGO to 1 for DeepSpeed.
    Worker:
      replicas: 2  # Number of nodes for training.
      template:
        spec:
          hostIPC: True
          nodeSelector:
            nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
          containers:
          - name: llama2-training-deepspeed-mpi
            image: dockerhub.kubekey.local/kubesphereio/llama2_demo:2023-10-25
            imagePullPolicy: IfNotPresent
            resources:
              limits:
                # TODO(yzhao): Add IB devices.
                nvidia.com/gpu: 2  # Number of GPUs required per replica.
