apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: llama2-finetuning-deepspeed
spec:
  slotsPerWorker: 1
  runPolicy:
    cleanPodPolicy: None  # No pods will be deleted after the job terminates.
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          # https://kubesec.io/basics/spec-hostipc/
          # https://www.fairwinds.com/blog/kubernetes-basics-tutorial-host-ipc-should-not-be-configured
          hostIPC: True  # Setting True for now. Subject to change.
          containers:
          - name: llama2-training-deepspeed-mpi
            # naming to docker.io/library/llama2_demo:2023-10-22
            image: sxwl/llama2-ft-test:latest
            imagePullPolicy: Always  # Not a big deal. More convenient for testing.
            command:
            - mpirun
            - -np
            - "12"
            - --allow-run-as-root
            - -bind-to
            - none
            - -map-by
            - slot
            - -x
            - LD_LIBRARY_PATH
            - -x
            - PATH
            - -x
            - NCCL_DEBUG=INFO
            - -x
            - NCCL_NET=IB
            - -x
            - NCCL_P2P_LEVEL=SYS
            - -x
            - NCCL_NET_GDR_READ=1
            - -x
            - NCCL_IB_CUDA_SUPPORT=1
            - -x
            - NCCL_NET_GDR_LEVEL=SYS
            - -x
            - NCCL_IB_GDR_LEVEL=SYS
            - -x
            - NCCL_DEBUG_SUBSYS=ALL
            - -x
            - NCCL_SOCKET_IFNAME=ibs1
            - -x
            - NCCL_IB_HCA=mlx5_
            - -mca
            - mpi_warn_on_fork
            - "0"
            - python3
            - llama2_demo.py
            - --deepspeed_mpi
            - --deepspeed
            volumeMounts:
            - name: mpi-hostfile
              mountPath: /llama2/hostfile
              subPath: hostfile
            env:
            - name: NCCL_TREE_THRESHOLD
              value: "0"  # Set NCCL tree threshold to 0 for DeepSpeed.
            - name: NCCL_ALGO
              value: "1"  # Set NCCL_ALGO to 1 for DeepSpeed.
    Worker:
      replicas: 3  # Number of nodes for training.
      template:
        spec:
          hostIPC: True
          containers:
          - name: llama2-training-deepspeed-mpi
            image: sxwl/llama2-ft-test:latest
            imagePullPolicy: Always  # Not a big deal. More convenient for testing.
            resources:
              limits:
                nvidia.com/gpu: 4  # Number of GPUs required per replica.
