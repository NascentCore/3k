{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.91\n",
      "Build cuda_12.2.r12.2/compiler.32965470_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
      "Collecting jax[cuda]\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/06/f3/c499d358dd7f267a63d7d38ef54aadad82e28d2c28bafff15360c3091946/jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib<=0.4.34,>=0.4.34 (from jax[cuda])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e4/b0/a5bd34643c070e50829beec217189eab1acdfea334df1f9ddb4e5f8bec0f/jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl (86.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes>=0.2.0 (from jax[cuda])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9a/5b/d47361f882ff2ae27d764f314d18706c69859da60a6c78e6c9e81714c792/ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.24 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax[cuda]) (1.26.4)\n",
      "Collecting opt-einsum (from jax[cuda])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m249.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.10 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax[cuda]) (1.14.0)\n",
      "Collecting jax-cuda12-plugin<=0.4.34,>=0.4.34 (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/37/b9/0d3bf6bb5909bde61e76e7ce9ee84c30c907e7d2005fb2b41e04c0c09444/jax_cuda12_plugin-0.4.34-cp310-cp310-manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jax-cuda12-pjrt==0.4.34 (from jax-cuda12-plugin<=0.4.34,>=0.4.34->jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2c/96/6c7162d57d13bf14cd2e70780c583bf5056e7cbc21a07ade6397ac80b3d4/jax_cuda12_pjrt-0.4.34-py3-none-manylinux2014_x86_64.whl (100.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: jax-cuda12-plugin 0.4.34 does not provide the extra 'with-cuda'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (12.1.105)\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/62/8f/cd3032281ba7bb531fe3159337af00c5c805fd6a31dc700f0715c8748c8c/nvidia_cuda_nvcc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (21.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.2/21.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /home/lanyun/miniconda3/envs/myenv/lib/python3.10/site-packages (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda\"->jax[cuda]) (12.6.20)\n",
      "Installing collected packages: jax-cuda12-pjrt, opt-einsum, nvidia-cuda-nvcc-cu12, ml-dtypes, jax-cuda12-plugin, jaxlib, jax\n",
      "Successfully installed jax-0.4.34 jax-cuda12-pjrt-0.4.34 jax-cuda12-plugin-0.4.34 jaxlib-0.4.34 ml-dtypes-0.5.0 nvidia-cuda-nvcc-cu12-12.6.77 opt-einsum-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install  -i  https://pypi.tuna.tsinghua.edu.cn/simple --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 11 02:16:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:12:00.0 Off |                  N/A |\n",
      "|  0%   23C    P8              18W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  | 00000000:13:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8              22W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 3090        On  | 00000000:48:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8              15W / 350W |  20762MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 3090        On  | 00000000:49:00.0 Off |                  N/A |\n",
      "|  0%   25C    P8              19W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 3090        On  | 00000000:89:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8              20W / 350W |  21376MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 3090        On  | 00000000:8A:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8              21W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 3090        On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8              21W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 3090        On  | 00000000:C2:00.0 Off |                  N/A |\n",
      "|  0%   24C    P8              17W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    2   N/A  N/A     32758      C   python                                    20746MiB |\n",
      "|    4   N/A  N/A     65127      C   ray::ServeReplica:llm:VLLMDeployment      21360MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59134/1991717721.py:2: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
      "  print(xla_bridge.get_backend().platform)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0),\n",
       " CudaDevice(id=1),\n",
       " CudaDevice(id=2),\n",
       " CudaDevice(id=3),\n",
       " CudaDevice(id=4),\n",
       " CudaDevice(id=5),\n",
       " CudaDevice(id=6),\n",
       " CudaDevice(id=7)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0),\n",
       " CudaDevice(id=1),\n",
       " CudaDevice(id=2),\n",
       " CudaDevice(id=3),\n",
       " CudaDevice(id=4),\n",
       " CudaDevice(id=5),\n",
       " CudaDevice(id=6),\n",
       " CudaDevice(id=7)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices(\"gpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 02:19:10.696378: W external/xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.6.77. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "# a function with some amount of calculations\n",
    "def f(x):\n",
    "  y1 = x + x*x + 3\n",
    "  y2 = x*x + x*x.T\n",
    "  return y1*y2\n",
    "\n",
    "# generate some random data\n",
    "x = np.random.randn(3000, 3000).astype('float32')\n",
    "jax_x_gpu = jax.device_put(jnp.array(x), jax.devices('gpu')[0])\n",
    "jax_x_cpu = jax.device_put(jnp.array(x), jax.devices('cpu')[0])\n",
    "\n",
    "# compile function to CPU and GPU backends with JAX\n",
    "jax_f_cpu = jax.jit(f, backend='cpu')\n",
    "jax_f_gpu = jax.jit(f, backend='gpu')\n",
    "\n",
    "# warm-up\n",
    "jax_f_cpu(jax_x_cpu)\n",
    "jax_f_gpu(jax_x_gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 ms ± 38.7 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 f(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.5 ms ± 1.73 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 f(jax_x_cpu).block_until_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.61 ms ± 300 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 jax_f_cpu(jax_x_cpu).block_until_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 ms ± 706 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 f(jax_x_gpu).block_until_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 μs ± 4.81 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n100 jax_f_gpu(jax_x_gpu).block_until_ready()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
