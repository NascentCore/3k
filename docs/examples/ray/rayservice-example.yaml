apiVersion: ray.io/v1
kind: RayService
metadata:
  name: llama-3-8b-ray
  namespace: public
spec:
  serveConfigV2: |
    applications:
    - name: llm
      route_prefix: /
      import_path: vllm_app:model 
      deployments:
      - name: VLLMDeployment
        max_ongoing_requests: 5
        autoscaling_config:
          min_replicas: 1
          initial_replicas: null
          max_replicas: 4
          target_ongoing_requests: 3.0
          metrics_interval_s: 10.0
          look_back_period_s: 30.0
          smoothing_factor: 1.0
          upscale_smoothing_factor: null
          downscale_smoothing_factor: null
          upscaling_factor: null
          downscaling_factor: null
          downscale_delay_s: 600.0
          upscale_delay_s: 30.0
      runtime_env:
        working_dir: "https://sxwl-dg.oss-cn-beijing.aliyuncs.com/ray/ray_vllm/va.zip"
  rayClusterConfig:
    enableInTreeAutoscaling: true
    autoscalerOptions:
      resources:
        limits:
          cpu: "8"
          memory: "20Gi"
          nvidia.com/gpu: "1"
        requests:
          cpu: "8"
          memory: "20Gi"
          nvidia.com/gpu: "1"
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
        num-cpus: "0"
      template:
        spec:
          containers:
            - name: ray-head
              image: sxwl-registry.cn-beijing.cr.aliyuncs.com/sxwl-ai/ray:v2
              env:
                - name: NVIDIA_VISIBLE_DEVICES
                  value: void
              resources:
                limits:
                  cpu: "2"
                  memory: "8Gi"
                requests:
                  cpu: "2"
                  memory: "8Gi"
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
    workerGroupSpecs:
      - replicas: 1
        minReplicas: 1
        maxReplicas: 4
        groupName: gpu-group
        rayStartParams: { "num-cpus": "1" }
        template:
          spec:
            containers:
              - name: llm
                image: sxwl-registry.cn-beijing.cr.aliyuncs.com/sxwl-ai/ray:v3
                env:
                  - name: PYTHONPATH
                    value: "$(PYTHONPATH):/app"
                resources:
                  limits:
                    cpu: "8"
                    memory: "20Gi"
                    nvidia.com/gpu: "1"
                  requests:
                    cpu: "8"
                    memory: "20Gi"
                    nvidia.com/gpu: "1"
                volumeMounts:
                  - mountPath: /dev/shm
                    name: cache-volume
                  - mountPath: /mnt/model
                    name: model
            # Please add the following taints to the GPU node.
            tolerations:
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
            volumes:
              - emptyDir:
                  medium: Memory
                  sizeLimit: 50Gi
                name: cache-volume
              - name: model
                persistentVolumeClaim:
                  claimName: llama31-8b-pvc
